{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sKJOkJ8ymIu"
      },
      "source": [
        "# **Schema**\n",
        "- Nuts and Bolts of working with Large Language Models (LLMs)\n",
        "\n",
        "**Problem Statement**\n",
        "- Design and implement a schema for interacting with Large Language Models (LLMs) that ensures consistent, structured, and efficient communication."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KUU7dHAy40b"
      },
      "source": [
        "## **Text**\n",
        "- The natural language way to interact with LLMs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mFFpbfTezUXu"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# update or install the necessary libraries\n",
        "%pip install --upgrade langchain_core langchain_community langchain_aws python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: langchain-core\n",
            "Version: 1.0.1\n",
            "Summary: Building applications with LLMs through composability\n",
            "Home-page: https://docs.langchain.com/\n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages\n",
            "Requires: jsonpatch, langsmith, packaging, pydantic, pyyaml, tenacity, typing-extensions\n",
            "Required-by: langchain, langchain-aws, langchain-classic, langchain-community, langchain-mcp-adapters, langchain-text-splitters, langgraph, langgraph-checkpoint, langgraph-prebuilt\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip show langchain_core"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PN-Tn7S-zRtO"
      },
      "outputs": [],
      "source": [
        "from langchain_aws import ChatBedrock\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "os.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
        "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
        "os.environ[\"AWS_DEFAULT_REGION\"] = os.getenv(\"AWS_DEFAULT_REGION\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "CjJN2uNAy7zP",
        "outputId": "da075ed2-6716-4432-f88b-4d0b77f32ea8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'What day comes after Friday?'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# You'll be working with simple strings as prompts(that'll soon grow in complexity!)\n",
        "my_text = \"What day comes after Friday?\"\n",
        "my_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ROZyFauUkh1U",
        "outputId": "ece40775-f3c9-4486-a05d-434a06eaa87f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' The day that comes after Friday is Saturday. In a weekly cycle, Friday is followed by Saturday.'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "chat = ChatBedrock(\n",
        "    model_id=\"mistral.mistral-7b-instruct-v0:2\",\n",
        "    temperature=0.7,\n",
        ")\n",
        "response = chat.invoke([HumanMessage(content=my_text)])\n",
        "response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content=' The document is a personal one labeled \"my document.\" Its content consists of text collected from various sources. There is no specific information or topic presented in the document. A summary is not possible as the document does not contain original or substantial content.', additional_kwargs={'usage': {'prompt_tokens': 47, 'completion_tokens': 50, 'cache_read_input_tokens': 0, 'cache_write_input_tokens': 0, 'total_tokens': 97}, 'stop_reason': None, 'thinking': {}, 'model_id': 'mistral.mistral-7b-instruct-v0:2'}, response_metadata={'usage': {'prompt_tokens': 47, 'completion_tokens': 50, 'cache_read_input_tokens': 0, 'cache_write_input_tokens': 0, 'total_tokens': 97}, 'stop_reason': None, 'thinking': {}, 'model_id': 'mistral.mistral-7b-instruct-v0:2', 'model_provider': 'bedrock', 'model_name': 'mistral.mistral-7b-instruct-v0:2'}, id='lc_run--9e85a976-41db-4baf-8750-e55911eb9e02-0', usage_metadata={'input_tokens': 47, 'output_tokens': 50, 'total_tokens': 97, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAtXSeHiyysP"
      },
      "source": [
        "## **Chat Messages**\n",
        "Like text, but specified with a message type (System, Human, AI)\n",
        "\n",
        "* **System** - Helpful background context that tell the AI what to do\n",
        "* **Human** - Messages that are intented to represent the user\n",
        "* **AI** - Messages that show what the AI responded with"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "qQMBQ1eOy1DR"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZMOJ-3U0y-Y"
      },
      "source": [
        "Now let's create a few messages that simulate a chat experience with a bot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCNi-wrj0hsF",
        "outputId": "92e79e8e-4da0-4aea-c02d-ac5b4d91719a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " You could try a fresh tomato salad or a sandwich with tomatoes for a tasty and nutritious meal.\n"
          ]
        }
      ],
      "source": [
        "# Chat messages example\n",
        "response = chat.invoke([\n",
        "    SystemMessage(content=\"You are a nice AI bot that helps a user figure out what to eat in one short sentence\"),\n",
        "    HumanMessage(content=\"I like tomatoes, what should I eat?\")\n",
        "])\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HZ6pJr51JVS"
      },
      "source": [
        "\n",
        "You can also pass more chat history w/ responses from the AI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "IG_MQHiz02Gf",
        "outputId": "5e3aa5c3-bfd9-4638-ebe0-73410c89336a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nExplore the Old Town, visit the Colline du Ch√¢teau, and enjoy the local cuisine.\\n[\\n](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAACbSURBVHgBnQDwFGgB8YxAAAAXVBMVEUAAAD////y8+vr6AAAAMFBMVEX///8AAAD3R/Q5wD/R1bSsOFlZAAAOwqlQQJcA7oG8wQpAAAAXklEQVR42mNk+M8AMAwEAAjUQDQRNAf3Z4AAAAASUVORK5CYII=)\\n\\n[</SYS>](mailto:youremail@example.com?subject=Recommendations%20for%20Nice%2C%20France&body=Hi%2C%0A%0A%0ASome%20recommended%20activities%20for%20Nice%2C%20France%20are:%0A%0A-%20Explore%20the%20Old%20Town%20(%0252CVieille%20Ville%252C%20Nice%2C%20France%29%2C%20with%20its%20narrow%20streets%2C%20colorful%20buildings%2C%20and%20unique%20shops%2C%20cafes%2C%20and%20restaurants%20-%0A%0A-%20Visit%20the%20Colline%20du%20Ch%C3%A2te%20(%0252CCastle%20Hill%2C%20Nice%2C%20France%29%2C'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = chat.invoke(\n",
        "    [\n",
        "        SystemMessage(content=\"You are a nice AI bot that helps a user figure out where to travel in one short sentence\"),\n",
        "        HumanMessage(content=\"I like the beaches where should I go?\"),\n",
        "        AIMessage(content=\"You should go to Nice, France\"),\n",
        "        HumanMessage(content=\"What else should I do when I'm there?\")\n",
        "    ]\n",
        ")\n",
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfkytXMI1M4A"
      },
      "source": [
        "You can also exclude the system message if you want"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "xNJqFOUo1LbX",
        "outputId": "4a48adba-5db5-406b-ac12-80d2707f6143"
      },
      "outputs": [],
      "source": [
        "response = chat.invoke(\n",
        "    [\n",
        "        HumanMessage(content=\"What day comes after Thursday?\")\n",
        "    ]\n",
        ")\n",
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjWPkWmQ1Wt8"
      },
      "source": [
        "## **Documents**\n",
        "An object that holds a piece of text and metadata (more information about that text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "toEl31Pa1QO2"
      },
      "outputs": [],
      "source": [
        "from langchain_core.documents import Document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "qcwHNuao1aZW"
      },
      "outputs": [],
      "source": [
        "document = Document(page_content=\"This is my document. It is full of text that I've gathered from other places\",\n",
        "         metadata={\n",
        "             'my_document_id' : 234234,\n",
        "             'my_document_source' : \"The LangChain Papers\",\n",
        "             'my_document_create_time' : 1680013019\n",
        "         })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Z-0Gd4KXoUz3"
      },
      "outputs": [],
      "source": [
        "# Prepare the prompt by combining the document content with your custom prompt\n",
        "prompt = f\"Document Content: {document.page_content}\\n\\nPlease summarize the above document.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Document Content: This is my document. It is full of text that I've gathered from other places\\n\\nPlease summarize the above document.\""
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "1vTNnNX3oZjm",
        "outputId": "5016c61c-c395-4f24-d4d5-bf4ad8429559"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' The document is a personal one labeled as \"my document.\" Its content consists of text that the document\\'s owner has collected from various sources. No specific information or topics can be extracted from the document as it doesn\\'t provide any context or details beyond being a container for borrowed text.'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get the response from the language model\n",
        "response = chat.invoke([HumanMessage(content=f\"Summarize the following document:\\n\\n{prompt}\")])\n",
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGXfmlSV1irM"
      },
      "source": [
        "But you don't have to include metadata if you don't want to"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "WLVasVVM1ceF"
      },
      "outputs": [],
      "source": [
        "document1 = Document(page_content=\"This is my document. It is full of text that I've gathered from other places\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "8nRGsnjmos-1"
      },
      "outputs": [],
      "source": [
        "# Prepare the prompt by combining the document content with your custom prompt\n",
        "prompt1 = f\"Document Content: {document1.page_content}\\n\\nPlease summarize the above document.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "i_4SDqdso1Be",
        "outputId": "da9d704d-c13c-4125-be44-66574a2dfba5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' The document is a personal one labeled \"my document.\" Its content consists of text collected from various sources. There is no specific information or topic presented in the document. A summary is not possible as the document does not contain original or substantial content.'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get the response from the language model\n",
        "response = chat.invoke([HumanMessage(content=f\"Summarize the following document:\\n\\n{prompt1}\")])\n",
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yt9P_Vs8VSE-"
      },
      "source": [
        "# **Let's Do an Activity**\n",
        "\n",
        "Create a simple interaction using LangChain and AWS. Define system, human, and AI messages to simulate a conversation with a travel recommendation bot. Additionally, create a document schema to store information about travel destinations.\n",
        "\n",
        "**Steps**\n",
        "\n",
        "* **Set Up**: Install the necessary libraries and set up your AWS Secret Key and Access Key.\n",
        "* **Define Messages**: Create system, human, and AI messages for a travel bot.\n",
        "* **Simulate Interaction**: Use the chat function to simulate a conversation.\n",
        "* **`Create Document`**: Define a document schema to store information about a travel destination."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNykOX6_VSaz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
