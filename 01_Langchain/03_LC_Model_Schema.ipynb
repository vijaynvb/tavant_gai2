{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sKJOkJ8ymIu"
      },
      "source": [
        "# **Schema**\n",
        "- Nuts and Bolts of working with Large Language Models (LLMs)\n",
        "\n",
        "**Problem Statement**\n",
        "- Design and implement a schema for interacting with Large Language Models (LLMs) that ensures consistent, structured, and efficient communication."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KUU7dHAy40b"
      },
      "source": [
        "## **Text**\n",
        "- The natural language way to interact with LLMs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mFFpbfTezUXu"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# update or install the necessary libraries\n",
        "%pip install --upgrade langchain_core langchain_community langchain_aws python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip show langchain_core"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PN-Tn7S-zRtO"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
          ]
        }
      ],
      "source": [
        "from langchain_aws import ChatBedrock\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "os.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
        "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
        "os.environ[\"AWS_DEFAULT_REGION\"] = os.getenv(\"AWS_DEFAULT_REGION\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "CjJN2uNAy7zP",
        "outputId": "da075ed2-6716-4432-f88b-4d0b77f32ea8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'what all education streams possible after 10th in india, wrap the response in html elments with ordered list and dont use new line characters in html content'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# You'll be working with simple strings as prompts(that'll soon grow in complexity!)\n",
        "my_text = \"what all education streams possible after 10th in india, wrap the response in html elments with ordered list and dont use new line characters in html content\"\n",
        "my_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ROZyFauUkh1U",
        "outputId": "ece40775-f3c9-4486-a05d-434a06eaa87f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' <html>\\n <body>\\n <ol>\\n <li>Science Stream: Physics, Chemistry, Biology, Mathematics, Computer Science</li>\\n <li>Commerce Stream: Accountancy, Economics, Business Studies, Mathematics, Statistics</li>\\n <li>Arts Stream: History, Geography, Political Science, English, Other Languages, Literature, Fine Arts</li>\\n <li>Vocational Stream: Agriculture, Engineering & Technology, Health & Allied Services, Home Science, Commerce, Information Technology, Visual & Performing Arts</li>\\n </ol>\\n </body>\\n</html>'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "chat = ChatBedrock(\n",
        "    model_id=\"mistral.mistral-7b-instruct-v0:2\",\n",
        "    temperature=0.7,\n",
        ")\n",
        "response = chat.invoke([HumanMessage(content=my_text)])\n",
        "response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content=' The day that comes after Friday is Saturday. In terms of numbers, if we consider Sunday as the first day of the week, then Friday is the fifth day and Saturday is the sixth day.', additional_kwargs={'usage': {'prompt_tokens': 14, 'completion_tokens': 40, 'cache_read_input_tokens': 0, 'cache_write_input_tokens': 0, 'total_tokens': 54}, 'stop_reason': None, 'thinking': {}, 'model_id': 'mistral.mistral-7b-instruct-v0:2'}, response_metadata={'usage': {'prompt_tokens': 14, 'completion_tokens': 40, 'cache_read_input_tokens': 0, 'cache_write_input_tokens': 0, 'total_tokens': 54}, 'stop_reason': None, 'thinking': {}, 'model_id': 'mistral.mistral-7b-instruct-v0:2', 'model_provider': 'bedrock', 'model_name': 'mistral.mistral-7b-instruct-v0:2'}, id='lc_run--61edba29-3a25-4823-ba26-747963190aee-0', usage_metadata={'input_tokens': 14, 'output_tokens': 40, 'total_tokens': 54, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAtXSeHiyysP"
      },
      "source": [
        "## **Chat Messages**\n",
        "Like text, but specified with a message type (System, Human, AI)\n",
        "\n",
        "* **System** - Helpful background context that tell the AI what to do\n",
        "* **Human** - Messages that are intented to represent the user\n",
        "* **AI** - Messages that show what the AI responded with"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "qQMBQ1eOy1DR"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZMOJ-3U0y-Y"
      },
      "source": [
        "Now let's create a few messages that simulate a chat experience with a bot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCNi-wrj0hsF",
        "outputId": "92e79e8e-4da0-4aea-c02d-ac5b4d91719a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Consider making a fresh tomato salad or a caprese appetizer for a delicious and satisfying meal.\n"
          ]
        }
      ],
      "source": [
        "# Chat messages example\n",
        "response = chat.invoke([\n",
        "    SystemMessage(content=\"You are a nice AI bot that helps a user figure out what to eat in one short sentence\"),\n",
        "    HumanMessage(content=\"I like tomatoes, what should I eat?\")\n",
        "])\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HZ6pJr51JVS"
      },
      "source": [
        "\n",
        "You can also pass more chat history w/ responses from the AI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "IG_MQHiz02Gf",
        "outputId": "5e3aa5c3-bfd9-4638-ebe0-73410c89336a"
      },
      "outputs": [],
      "source": [
        "response = chat.invoke(\n",
        "    [\n",
        "        SystemMessage(content=\"You are a nice AI bot that helps a user figure out where to travel in one short sentence\"),\n",
        "        HumanMessage(content=\"I like the beaches where should I go?\"),\n",
        "        AIMessage(content=\"You should go to Nice, France\"),\n",
        "        HumanMessage(content=\"What else should I do when I'm there?\")\n",
        "    ]\n",
        ")\n",
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfkytXMI1M4A"
      },
      "source": [
        "You can also exclude the system message if you want"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "xNJqFOUo1LbX",
        "outputId": "4a48adba-5db5-406b-ac12-80d2707f6143"
      },
      "outputs": [],
      "source": [
        "response = chat.invoke(\n",
        "    [\n",
        "        HumanMessage(content=\"What day comes after Thursday?\")\n",
        "    ]\n",
        ")\n",
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjWPkWmQ1Wt8"
      },
      "source": [
        "## **Documents**\n",
        "An object that holds a piece of text and metadata (more information about that text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "toEl31Pa1QO2"
      },
      "outputs": [],
      "source": [
        "from langchain_core.documents import Document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "qcwHNuao1aZW"
      },
      "outputs": [],
      "source": [
        "document = Document(page_content=\"This is my document. It is full of text that I've gathered from other places\",\n",
        "         metadata={\n",
        "             'my_document_id' : 234234,\n",
        "             'my_document_source' : \"The LangChain Papers\",\n",
        "             'my_document_create_time' : 1680013019\n",
        "         })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Z-0Gd4KXoUz3"
      },
      "outputs": [],
      "source": [
        "# Prepare the prompt by combining the document content with your custom prompt\n",
        "prompt = f\"Document Content: {document.page_content}\\n\\nPlease summarize the above document.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Document Content: This is my document. It is full of text that I've gathered from other places\\n\\nPlease summarize the above document.\""
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "1vTNnNX3oZjm",
        "outputId": "5016c61c-c395-4f24-d4d5-bf4ad8429559"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' The document is a personal document labeled as \"my document.\" Its content consists of text that the document owner has collected from various sources. There is no specific information or topic discussed within the text.'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get the response from the language model\n",
        "response = chat.invoke([HumanMessage(content=f\"Summarize the following document:\\n\\n{prompt}\")])\n",
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGXfmlSV1irM"
      },
      "source": [
        "But you don't have to include metadata if you don't want to"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLVasVVM1ceF"
      },
      "outputs": [],
      "source": [
        "document1 = Document(page_content=\"This is my document. It is full of text that I've gathered from other places\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nRGsnjmos-1"
      },
      "outputs": [],
      "source": [
        "# Prepare the prompt by combining the document content with your custom prompt\n",
        "prompt1 = f\"Document Content: {document1.page_content}\\n\\nPlease summarize the above document.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "i_4SDqdso1Be",
        "outputId": "da9d704d-c13c-4125-be44-66574a2dfba5"
      },
      "outputs": [],
      "source": [
        "# Get the response from the language model\n",
        "response = chat.invoke([HumanMessage(content=f\"Summarize the following document:\\n\\n{prompt1}\")])\n",
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yt9P_Vs8VSE-"
      },
      "source": [
        "# **Let's Do an Activity**\n",
        "\n",
        "Create a simple interaction using LangChain and AWS. Define system, human, and AI messages to simulate a conversation with a travel recommendation bot. Additionally, create a document schema to store information about travel destinations.\n",
        "\n",
        "**Steps**\n",
        "\n",
        "* **Set Up**: Install the necessary libraries and set up your AWS Secret Key and Access Key.\n",
        "* **Define Messages**: Create system, human, and AI messages for a travel bot.\n",
        "* **Simulate Interaction**: Use the chat function to simulate a conversation.\n",
        "* **`Create Document`**: Define a document schema to store information about a travel destination."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNykOX6_VSaz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
